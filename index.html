<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Efthymios Tzinis</title>
	<meta name="viewport" content="width=device-width, initial-scale=1, height=device-height">
	<meta name="description" content="Welcome to Efthymios Tzinis' homepage!" />
	<meta name="keywords" content="Efthymios Tzinis, Tzinis, Thymios, Efthymios, Homepage, Website,
								   Google research, AudioScope, RemixIT, Sudo rm -rf, PhD, University of Illinois,
								   Urbana-Champaign, National Technical University of Athens, UIUC, NTUA, Neural Networks,
								   Artificial Intelligence, Machine Learning, Deep Learning,
								   Audio Processing, Audio Source Separation, Manifold Learning,
								   Speech Emotion Recognition" />
	<meta name="author" content="" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Efthymios Tzinis"/>
	<meta property="og:image" content="https://etzinis.com/images/prof_pic.jpg" />
<meta property="og:url" content="https://etzinis.com"/>
	<meta property="og:site_name" content="Efthymios Tzinis' website"/>
	<meta property="og:description" content="Welcome to Efthymios Tzinis' homepage!"/>
	<meta name="twitter:title" content="Efthymios Tzinis" />
	<meta name="twitter:image" content="https://etzinis.com/images/prof_pic.jpg" />
	<meta name="twitter:url" content="https://etzinis.com" />
	<meta name="twitter:card" content="summary" />
	<meta name="twitter:description" content="Welcome to Efthymios Tzinis' homepage!" />
	
	<link rel="shortcut icon" href="images/manifold_img-min.png">
	<link rel="icon" type="image/gif" href="images/manifold_img-min.png">
	<!--<link rel="image_src" href="https://etzinis.com/images/manifold_img-min.png" />-->
	<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
	

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

	<script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script> 
	<script type="text/javascript">
// 	particlesJS("particles-js", {"particles":{"number":{"value":10,"density":{"enable":true,"value_area":800}},"color":{"value":"#000000"},"shape":{"type":"circle","stroke":{"width":0,"color":"#000000"},"polygon":{"nb_sides":5},"image":{"src":"img/github.svg","width":100,"height":100}},"opacity":{"value":0.25,"random":false,"anim":{"enable":false,"speed":1,"opacity_min":0.1,"sync":false}},"size":{"value":3,"random":true,"anim":{"enable":false,"speed":40,"size_min":0.1,"sync":false}},"line_linked":{"enable":true,"distance":150,"color":"#ffffff","opacity":0.3,"width":1},"move":{"enable":true,"speed":3,"direction":"none","random":false,"straight":false,"out_mode":"out","bounce":false,"attract":{"enable":false,"rotateX":600,"rotateY":1200}}},"interactivity":{"detect_on":"canvas","events":{"onhover":{"enable":true,"mode":"repulse"},"onclick":{"enable":true,"mode":"push"},"resize":true},"modes":{"grab":{"distance":400,"line_linked":{"opacity":1}},"bubble":{"distance":400,"size":40,"duration":2,"opacity":8,"speed":3},"repulse":{"distance":200,"duration":0.4},"push":{"particles_nb":4},"remove":{"particles_nb":2}}},"retina_detect":true});var count_particles, stats, update; stats = new Stats; stats.setMode(0); stats.domElement.style.position = 'absolute'; stats.domElement.style.left = '0px'; stats.domElement.style.top = '0px'; document.body.appendChild(stats.domElement); count_particles = document.querySelector('.js-count-particles'); update = function() { stats.begin(); stats.end(); if (window.pJSDom[0].pJS.particles && window.pJSDom[0].pJS.particles.array) { count_particles.innerText = window.pJSDom[0].pJS.particles.array.length; } requestAnimationFrame(update); }; requestAnimationFrame(update);;
	</script>
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<!--<link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">-->
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
		
	<div id="particles-js">
	</div>
	<script src="js/app.js"></script>
		
	<div id="colorlib-page">
		<div class="container-wrap">
			<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle"
			   data-target="#navbar" aria-expanded="false"
			   aria-controls="navbar"><i></i></a>
			<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
				<div class="text-center">
					<div class="author-img" style="background-image: url(images/prof_pic.jpg);"></div>
					<h1 id="colorlib-logo" style="text-align: center">Efthymios Tzinis</h1>
					<!--<p style="color:blue;font-size:46px;">-->
					<!--I'm a big, blue, <strong>strong</strong> paragraph-->
					<!--</p>-->
					<h4 id="colorlib-logo" style="text-align: center; font-size: 12px">
					Research Scientist at Google </h4>
					<h4 id="colorlib-logo" style="text-align: center; font-size: 12px">
					 </h4>
					<br>
					<!--<span class="position"><a href="#">Phd Student at University of Illinois at Urbana-Champaign</a> in Philippines</span>-->
				</div>
				<nav id="colorlib-main-menu" role="navigation" class="navbar">
					<div id="navbar" class="collapse" style='text-decoration: none'>
						<ul>
							<li class="active"><a href="#" data-nav-section="home">Home</a></li>
							<li><a href="#" data-nav-section="news">News</a></li>
							<!--<li><a href="#" data-nav-section="about">About</a></li>-->
							<!--<li><a href="#" data-nav-section="services">Services</a></li>-->
							<li><a href="#" data-nav-section="education">Education</a></li>
							<!--<li><a href="#" data-nav-section="experience">Experience</a></li>-->
							<li><a href="#" data-nav-section="work-experience">Work Experience</a></li>
							<li><a href="#" data-nav-section="papers">Research Papers</a></li>
<!--							<li><a href="#" data-nav-section="blog">Demos and Blog</a></li>-->
							<li><a href="#" data-nav-section="contact">Contact Me</a></li>
						</ul>
					</div>
				</nav>
				
				
				
	
				<div class="colorlib-footer">
					<ul>
						<li><a href="https://twitter.com/etzinis"><i class="icon-twitter2"></i></a></li>
						<li><a href="https://scholar.google.gr/citations?user=IuKsc4IAAAAJ&hl=en&oi=ao"><i class="ai ai-google-scholar-square ai-3x"></i></a></li>
						<!--<li><a href="https://www.researchgate.net/profile/Efthymios_Tzinis"><i class="ai ai-researchgate-square ai-3x"></i></a></li>-->
						<li><a href="https://www.linkedin.com/in/etzinis/"><i class="icon-linkedin2"></i></a></li>
						<li><a href="https://github.com/etzinis"><i class="icon-github"></i></a></li>
						<li><a href="./files/academic_cv_etzinis.pdf"><i class="ai ai-cv ai-3x"></i></a></li>
						<!--<br>-->
						<!--<li><a href="https://plus.google.com/u/0/106534973647151270598"><i class="icon-google2"></i></a></li>-->
						<!--<li><a href="https://www.facebook.com/etzinis">-->
						<!--<i class="icon-facebook2"></i></a></li>-->
					</ul>
				</div>
			
	
			</aside>
	
		<div id="colorlib-main">
			<br> <br>
			<section class="colorlib-about" data-section="home" >
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12 col-md-offset-3 col-md-pull-3">
							<div class="row animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">Let me introduce myself</span>
										<h2 class="colorlib-heading">Hi there! My name is Thymios!</h2>
									</div>
								</div>
								<div class="col-md-12">
									I am a research scientist at <a href="https://research.google/people/efthymios-tzinis/"> Google</a> working on
									uni- and multi-modal sound separation and sound understanding in general. I got my Ph.D. from the
									<a href="https://cs.illinois.edu/">Computer Science (CS)</a> department
									at the <a href="https://www.illinois.edu/">University of Illinois Urbana-Champaign (UIUC)</a>.
									During my PhD, I have also conducted research at <a href="https://ai.google/">Google AI</a>, <a href="https://www.merl.com/">Mitsubishi Electric Research Laboratories (MERL)</a>
									and <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Reality Labs at Meta (ex. FRL)</a>. 
									Before that, I graduated with a diploma (Bachelor and MEng equivalent) in <a href="https://www.ece.ntua.gr/en">
									Electrical and Computer Engineering (ECE)</a> from the <a href="https://www.ece.ntua.gr/en">
									National Technical University of Athens (NTUA)</a>.
									
									
								</div >
								
								<div class="col-md-12" style="padding-top: 20px">
								My current research focuses on developing and utilizing efficient
									<a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural networks</a>
									towards more generalizable audio and audio-visual
									<a href="https://en.wikipedia.org/wiki/Signal_separation">source separation</a>.
									I am particularly interested in
									<a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised</a>
									ways of learning directly from mixtures of sounds as well as
<!--									<a href="https://en.wikipedia.org/wiki/Federated_learning">federated learning</a>-->
									algorithms which work under realistic non-IID settings.
									For more information, please check my <a href="./files/academic_cv_etzinis.pdf">academic CV</a>.
									If you are interested in working with me in exciting new research ideas and potential
									Pixel-phone features please email me your CV and explain briefly your research interests.
								</div >

								<div class="col-md-12" style="padding-top: 20px">
								Besides research, I love traveling,
								playing the guitar and playing soccer.
								During summer vacations, I spend most of my time 
								<a href="https://youtube.com/shorts/6ixTpb6U-qk?feature=share">playing beach rackets</a>
								<!--<a href="./images/beach_racket.png">beach rackets</a>-->
								especially at the beautiful island of
								<a href="https://www.google.com/search?q=Santorini&source=lnms&tbm=isch&sa=X&ved=0ahUKEwj735GeqvTfAhWPyIMKHWuDCmoQ_AUIDigB&biw=2061&bih=1058">Santorini</a>,
								where I also come from.
								If you also like etymology, 
								<a href="https://translate.google.com/?sl=en&tl=el&text=Thymios&op=translate">
								Thymios</a>
								derives
								from the Ancient Greek name
								“Euthýmios (Ευθύμιος)”,
								composed of two elements: “eû ‎(εὖ)” (well)
								plus “thūmós (θῡμός)”
								(soul, as the seat of emotion,
								feeling, life, desire, will, temper, passion),
								meaning “in good spirits,
								of good cheer, clear”.  
								</div>
								
								
								
							</div>
						</div>	
					</div>
				</div>
			</section>
			
			<section class="colorlib-about" data-section="news">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">What's up?</span>
										<h2 class="colorlib-heading">News Feed</h2>
									</div>
								</div>
							</div>
							
							<div class="row animate-box" data-animate-effect="fadeInTop"
								 style="height: 600px; overflow-y: scroll;">
							    
							    
							    <div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 07/29/2022</strong>
							            <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Proud to be a Google PhD fellow! <a href="https://t.co/ZiSypgoFBs">https://t.co/ZiSypgoFBs</a></p>&mdash; Efthymios Tzinis (@ETzinis) <a href="https://twitter.com/ETzinis/status/1552812143434678278?ref_src=twsrc%5Etfw">July 29, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
									</div>
								</div>
								
								<div class="col-md-12" >
									<div class="services paper-acc">
										<span>
										<i class="icon-paper"></i>
										</span> 
										<span class="text-of-icon">Paper Accepted!</span>
										<strong class='date'> 07/24/2022</strong>
										I am 😃 that we will present AudioScopeV2 at ECCV2022! If you want to learn about improved audio-visual attention models and calibration for on-screen sound separation check our paper 
										<a href="https://google-research.github.io/sound-separation/papers/audioscope-v2/">[project page]</a>
										<a href="https://github.com/google-research/sound-separation/tree/master/datasets/audioscope-v2">[datasets]</a>
										<!--<a href="https://arxiv.org/abs/2110.10103"><i width="4" class="icon-file-pdf"></i></a>-->
										<div style="width: 100%; height:30%;">
                                        <blockquote class="twitter-tweet"><p lang="en" dir="ltr">AudioScopeV2: Audio-Visual Attention Architectures for Calibrated Open-Domain On-Screen Sound Separation<br>abs: <a href="https://t.co/haFWFL78pq">https://t.co/haFWFL78pq</a> <a href="https://t.co/ws0JLMTOOm">pic.twitter.com/ws0JLMTOOm</a></p>&mdash; AK (@_akhaliq) <a href="https://twitter.com/_akhaliq/status/1551335253683408898?ref_src=twsrc%5Etfw">July 24, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>                                        </div>
									</div>
								</div>

							    
							    <div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 06/29/2022</strong>
										I got mentioned as a <a href="https://icml.cc/Conferences/2022/Reviewers">"highlighted reviewer for ICML 2022 (top 10%)!"</a>
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 04/20/2022</strong>
										I got mentioned as a <a href="https://iclr.cc/Conferences/2022/Reviewers">"highlighted reviewer for ICLR 2022 (top 8.8%)!"</a>
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services talk">
										<span>
										<i class="icon-air-play"></i>
										</span> 
										<span class="text-of-icon"> Presentation</span>
										<strong class='date'> 04/20/2022</strong>
										I am giving a virtual presention of <em>RemixIT</em> 
									    at <strong>ICASSP 2022</strong>! You can learn more here:
                                        <blockquote class="twitter-tweet"><p lang="en" dir="ltr">The presentation of RemixIT is online!🎉 Learn how to perform self-supervised speech enhancement without the need of a single in-domain waveform (neither speech nor noise)!🤩<br><br>ICASSP paper: <a href="https://t.co/BKdrInQktY">https://t.co/BKdrInQktY</a><br>Longer version: <a href="https://t.co/doNfluZNkt">https://t.co/doNfluZNkt</a><a href="https://t.co/0v8jjlEWPb">https://t.co/0v8jjlEWPb</a></p>&mdash; Efthymios Tzinis (@ETzinis) <a href="https://twitter.com/ETzinis/status/1516570497558921226?ref_src=twsrc%5Etfw">April 20, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>									</div>
								</div>
							    
							    <div class="col-md-12" >
									<div class="services paper-acc">
										<span>
										<i class="icon-paper"></i>
										</span> 
										<span class="text-of-icon">Paper Accepted!</span>
										<strong class='date'> 01/27/2022</strong>
										Continual self-training with bootstrapped remixing for speech enhancement at <strong>ICASSP 2022</strong>! 
										Check our cool paper, 
										<a href="https://arxiv.org/abs/2110.10103">[pdf]</a>
										<!--<a href="https://arxiv.org/abs/2110.10103"><i width="4" class="icon-file-pdf"></i></a>-->
										<div style="width: 100%; height:30%;">
                                        <blockquote  class="twitter-tweet"><p 
                                        lang="en" dir="ltr">RemixIT got accepted in <a 
                                        href="https://twitter.com/ieeeICASSP?ref_src=twsrc%5Etfw">@ieeeICASSP</a> 🎉🥳, 
                                        a longer version with deeper analysis is coming soon! Check how our self-training method 
                                        can train denoising models WITHOUT a single in-domain isolated waveform! <a 
                                        href="https://t.co/nrFxfhBtxx">https://t.co/nrFxfhBtxx</a></p>&mdash; Efthymios Tzinis (@ETzinis) 
                                        <a href="https://twitter.com/ETzinis/status/1486508643914862597?ref_src=twsrc%5Etfw">January 27, 2022
                                        </a></blockquote> <script style="width: 100%; height:30%;" async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                                        </div>
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 10/14/2021</strong>
										I was recognized as an <a href="https://nips.cc/Conferences/2021/ProgramCommittee">outstanding reviewer (top 8%)</a>
										for the <a href="https://nips.cc/Conferences/2021/ProgramCommittee">NeurIPS 2021</a> conference!
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 09/29/2021</strong>
										I was nominated as one of the four UIUC's representatives for the renowned world-wide
										<a href="https://research.google/outreach/phd-fellowship/">"Google PhD Fellowship"</a>!
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services talk">
										<span>
										<i class="icon-air-play"></i>
										</span> 
										<span class="text-of-icon"> Presentation</span>
										<strong class='date'> 09/23/2021</strong>
										I am giving a virtual presention of our paper <em>"Separate but Together: Unsupervised Federated Learning for Speech Enhancement from Non-IID Data."</em> 
									    at <strong>WASPAA 2021</strong>! You can check the video-presentation
										<a href="https://www.youtube.com/watch?v=nJ8knZGaUKg">here</a>!
										<a href="https://arxiv.org/pdf/2105.04727.pdf">[paper]</a>
										<a href="https://github.com/etzinis/fedenhance">[code]</a>
										<a href="https://drive.google.com/file/d/12osKk_mcyxv7EpX_A-PpWmLnuh99uSWM/view?usp=sharing">[slides]</a>.
										
										<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Here is the virtual presentation of our WASPAA 21&#39; paper: Separate but together: &quot;Unsupervised Federated Learning for Speech Enhancement from non-IID Data&quot; <br>arxiv: <a href="https://t.co/jnGU8gR6Sp">https://t.co/jnGU8gR6Sp</a><br>code: <a href="https://t.co/Sxdl5rimLO">https://t.co/Sxdl5rimLO</a><br>video: <a href="https://t.co/1gTUQ7n7SY">https://t.co/1gTUQ7n7SY</a></p>&mdash; Efthymios Tzinis (@ETzinis) <a href="https://twitter.com/ETzinis/status/1441164359686926336?ref_src=twsrc%5Etfw">September 23, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services change">
										<span>
										<i class="icon-flag"></i>
										</span> 
										<span class="text-of-icon"> Status Change</span>
										<strong class='date'> 09/20/2021</strong>
									    I am going to work as a student researcher for
									    <a href="https://www.merl.com/">Mitsubishi Electric Research Laboratories (MERL)</a>
									    where I will be managed by Dr. <a href="https://scholar.google.gr/citations?user=JVkh89YAAAAJ&hl=en">Gordon Wichern</a> and by Dr.
									    <a href="https://scholar.google.gr/citations?user=aUpxty8AAAAJ&hl=en">Jonathan Le Roux</a>.
									</div>
								</div>
								
								<div class="col-md-12">
									<div class="services talk">
										<span>
										<i class="icon-air-play"></i>
										</span> 
										<span class="text-of-icon"> Presentation</span>
										<strong class='date'> 06/25/2021</strong>
										We gave a talk with John Hershey at a <strong>CVPR 2021</strong> workshop
								        about self-supervised audio-visual sound separation! 
								        <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Want to make computers that can see *and* hear? Come to the CVPR Sight and Sound workshop today!<br>Schedule: <a href="https://t.co/iVMEb7jxKK">https://t.co/iVMEb7jxKK</a><br><br>Invited talks by: <a href="https://twitter.com/justin_salamon?ref_src=twsrc%5Etfw">@justin_salamon</a>, <a href="https://twitter.com/ChenliangXu?ref_src=twsrc%5Etfw">@ChenliangXu</a>, Kristen Grauman, <a href="https://twitter.com/dimadamen?ref_src=twsrc%5Etfw">@dimadamen</a>, <a href="https://twitter.com/gan_chuang?ref_src=twsrc%5Etfw">@gan_chuang</a>, John Hershey, <a href="https://twitter.com/ETzinis?ref_src=twsrc%5Etfw">@ETzinis</a>, and James Traer <a href="https://t.co/xRc3vqK5i4">pic.twitter.com/xRc3vqK5i4</a></p>&mdash; Andrew Owens (@andrewhowens) <a href="https://twitter.com/andrewhowens/status/1406615344698040331?ref_src=twsrc%5Etfw">June 20, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                                        <blockquote class="twitter-tweet"><p lang="en" dir="ltr">In case you missed our talk with John at <a href="https://twitter.com/hashtag/CVPR2021?src=hash&amp;ref_src=twsrc%5Etfw">#CVPR2021</a>&#39;s sight and sound workshop about self-supervised on-screen sound separation and Audioscope 2.0, you can find it here!<br>arxiv: <a href="https://t.co/pPsNigeSNM">https://t.co/pPsNigeSNM</a><br>Talk: <a href="https://t.co/9BmCTd7N1m">https://t.co/9BmCTd7N1m</a></p>&mdash; Efthymios Tzinis (@ETzinis) <a href="https://twitter.com/ETzinis/status/1408478877396131846?ref_src=twsrc%5Etfw">June 25, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>									</div>
								</div>
							    
							    <div class="col-md-12" >
									<div class="services paper-acc">
										<span>
										<i class="icon-paper"></i>
										</span> 
										<span class="text-of-icon">Paper Accepted!</span>
										<strong class='date'> 06/20/2021</strong>
										Unsupervised federated learning for speech enhancement is going to be presented at <strong>WASPAA 2021</strong>! Check our cool paper,
										<em>"Separate but Together: Unsupervised Federated Learning for Speech Enhancement from non-IID Data."</em> here:
										<a href="https://arxiv.org/pdf/2105.04727.pdf">[pdf]</a>
										<a href="https://github.com/etzinis/fedenhance">[code]</a>
										<a href="https://www.youtube.com/watch?v=nJ8knZGaUKg">[video]</a>
									</div>
								</div>
							    
							    <div class="col-md-12">
									<div class="services change">
										<span>
										<i class="icon-flag"></i>
										</span> 
										<span class="text-of-icon"> Status Change</span>
										<strong class='date'> 05/17/2021</strong>
									    I am going to spend my summer as a research intern for <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Facebook Reality Labs (FRL)</a>
									    where I will be supervised by Dr. <a href="https://scholar.google.com/citations?user=HH5cCX0AAAAJ&hl=en" > Anurag Kumar </a>!
									</div>
								</div>
								<div class="col-md-12">
									<div class="services change">
										<span>
										<i class="icon-flag"></i>
										</span> 
										<span class="text-of-icon"> Status Change</span>
										<strong class='date'> 05/07/2021</strong>
                                        After a long and fruitful collaboration with the sound separation team at Google AI Perception, it's time to say goodbye!
                                        I would like to express my sincere gratitude towards Scott Wisdom and John Hershey who were not simply my managers but also acted as my
                                        advisors and mentors! We did great things together, I will miss you guys!
									</div>
								</div>
							    <div class="col-md-12">
									<div class="services talk">
										<span>
										<i class="icon-air-play"></i>
										</span> 
										<span class="text-of-icon"> Presentation</span>
										<strong class='date'> 05/02/2021</strong>
										I am giving a virtual presention of our paper <em>"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds."</em> 
									    at <strong>ICLR 2021</strong>! You can check the video-presentation
										<a href="https://iclr.cc/virtual/2021/poster/3161">here</a>!
										<a href="https://openreview.net/pdf?id=MDsQkFP1Aw">[paper]</a>
										<a href="https://iclr.cc/media/Slides/iclr/2021/virtual(03-16-00)-03-16-00UTC-3161-into_the_wild.pdf">[slides]</a>.
									    <blockquote class="twitter-tweet"><p lang="en" dir="ltr">If you want to separate on-screen sounds from unlabeled in-the-wild videos you can check Audioscope online now at <a href="https://twitter.com/iclr_conf?ref_src=twsrc%5Etfw">@iclr_conf</a> poster session 2! link: <a href="https://t.co/Hgs5dpgQyJ">https://t.co/Hgs5dpgQyJ</a><br>webpage: <a href="https://t.co/mznOkHciGU">https://t.co/mznOkHciGU</a><br><br>Essentially how do you isolate only the bird chirping 🐦? <a href="https://t.co/sWBiwKzgaH">pic.twitter.com/sWBiwKzgaH</a></p>&mdash; Efthymios Tzinis (@ETzinis) <a href="https://twitter.com/ETzinis/status/1389249336178061317?ref_src=twsrc%5Etfw">May 3, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
									</div>
								</div>
								
								<div class="col-md-12">
									<div class="services honor">
										<span>
										<i class="icon-star3"></i>
										</span>
										<span class="text-of-icon">Honors & Awards</span>
										<strong class='date'> 04/28/2021</strong>
										I was chosen as a finalist (top 3.5% of the applications) for the renowned
										<a href="https://research.fb.com/blog/2021/04/announcing-the-recipients-of-the-2021-facebook-fellowship-awards/">"Facebook PhD Fellowship"</a>.
									</div>
								</div>
							    
							    <div class="col-md-12" >
									<div class="services paper-acc">
										<span>
										<i class="icon-paper"></i>
										</span> 
										<span class="text-of-icon">Paper Accepted!</span>
										<strong class='date'> 01/28/2021</strong>
										Our paper with Dimitris <em>"Unified Gradient Reweighting for Model Biasing with Applications to Source Separation"</em>
										has been accepted at <strong>ICASSP 2021</strong>!
										Please take a look at how you can exploit biases in NNs here:
										<a href="https://arxiv.org/pdf/2010.13228.pdf">[pdf]</a>
										<a href="https://github.com/etzinis/biased_separation">[code]</a>
									</div>
								</div>
							    
							    <div class="col-md-12" >
									<div class="services paper-acc">
										<span>
										<i class="icon-paper"></i>
										</span> 
										<span class="text-of-icon">Paper Accepted!</span>
										<strong class='date'> 01/12/2021</strong>
										AudioScope has been accepted at <strong>ICLR 2021</strong>!
										You can take a look at our paper: 
										<em>"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds"</em>
										<a href="https://openreview.net/pdf?id=MDsQkFP1Aw">[pdf]</a>
									</div>
								</div>

								
							</div>
						</div>
					</div>
				</div>
			</section>
			<section class="colorlib-experience" data-section="education">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">Education Timeline</span>
							<h2 class="colorlib-heading animate-box">Education</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">
					         
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/uiuc.jpg'></i class="icon-leaf">
					               </div>
					               <div class="timeline-label">
					               	<h2>PhD in Computer Science (CS)
									at the <br>
									<a href="https://cs.illinois.edu/">University of Illinois at Urbana-Champaign (UIUC)</a>
									<br> <span><strong>Urbana-Champaign, Illinois, USA</strong> | Aug 2018 - May 2023</span> </h2>
									<ul>
										<li>Area: <strong><em>Artificial Intelligence</em></strong></li>
										<li>Thesis: <strong><em>Unsupervised sound separation </em></strong>
										<a href="https://www.ideals.illinois.edu/items/127515">[pdf]</a>
										<a href="https://docs.google.com/presentation/d/1Ec7POwKlQwrk7j1-Qk0ZnpFNaJj-PmT1/edit?usp=sharing&ouid=106534973647151270598&rtpof=true&sd=true">[slides]</a>
										</li>
										<li>Advisor: Prof. <a href="https://paris.cs.illinois.edu/">Paris Smaragdis</a></li>
										<li>Current GPA: <strong><em>4.00/4.00</em></strong></li>
										<!--<li>Selected Courses: Computational Inference and Learning, Machine Learning for Signal Processing, -->
										<!--Optimization in Computer Vision, Machine Learning, Deep Learning, Deep Learning Theory,-->
										<!--Probabilistic and Approximate Computation</li>-->
									</ul>
					               </div>
					            </div>
					         </article>
							 
							 
							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/ntua.jpg'></img>
					               </div>
					               <div class="timeline-label">
					               	<h2>Diploma (BS + Meng) in Electrical and Computer Engineering (ECE)
									at the <br>
									<a href="https://www.ece.ntua.gr/en">
										National Technical University of Athens (NTUA)</a>
									<br><span><strong>Athens, Greece</strong> | Oct 2012 - Jun 2018</span></h2>
									<ul>
										<li>Area: <strong><em>Computer Science</em></strong></li>
										<li><strong><em>Highest Honors - top 2%</em></strong></li>
										<li>GPA: <strong><em>Cumulative 9.36/10.00 | Major 9.56/10.00</em></strong></li>
										<li>Thesis: <strong><em>"Manifold Learning and Nonlinear Recurrence
										Dynamics for Speech Emotion Recognition on Various Timescales"</em></strong>
										<a href="https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/47369/etzinis_thesis_english.pdf?sequence=1&isAllowed=y">[pdf]</a>
										<a href="https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/47369/etzinis_thesis_presentation.pdf?sequence=3&isAllowed=y">[slides]</a>
										</li>
										<li>Advisor: Prof. <em>
										<a href="https://scholar.google.com/citations?user=pBQViyUAAAAJ&hl=en">Alexandros Potamianos</a></em></li>
									</ul>
					               </div>
					            </div>
					         </article>
			
			
					         <article class="timeline-entry begin animate-box" data-animate-effect="fadeInBottom">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-none">
					               </div>
					            </div>
					         </article>
					         
					      </div>
					   </div>
				   </div>
				</div>
					
<!--				<p style="text-align: center" class="animate-box" data-animate-effect="fadeInBottom">-->
<!--					For more information, please check my <a href="./files/academic_cv_etzinis.pdf">academic CV</a>.</p>-->
					
			</section>
			
			
			<section class="colorlib-experience" data-section="work-experience">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">Professional Timeline</span>
							<h2 class="colorlib-heading animate-box">Work Experience</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">
				             
				             <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/google_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Scientist at
									<a href="https://ai.google/">Google</a>
									<br> <span> <strong>Cambridge, Massachusetts, USA</strong> | June 2023 - Present</span> </h2>
					                  <p> Audio-visual and audio sound separation in Pixel and more. </p>
					               </div>
					            </div>
					         </article>

							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/google_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Intern at
									<a href="https://ai.google/">Google AI</a>
									<br> <span> <strong>Cambridge, Massachusetts, USA</strong> | May 2022 - Aug 2022</span> </h2>  
					                  <p> Next-level of audio-visual sound source separation. </p>
					               </div>
					            </div>
					         </article>
				             
				             
				             <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/merl_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Student Researcher at
									<a href="https://www.merl.com/">Mitsubishi Electric Research Laboratories (MERL)</a>
									<br> <span> <strong>Urbana, Illinois, USA</strong> | Sep 2021 - May 2022</span> </h2>  
					                  <p> Seamless audio source separation.</p>
					               </div>
					            </div>
					         </article>
					         
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/uiuc.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Graduate Teaching & Research Assistant at
									<a href="https://ece.illinois.edu/directory/profile/paris">Audio Lab UIUC</a>
									<br> <span> <strong>Urbana-Champaign, Illinois, USA</strong> | Aug 2018 - May 2022</span> </h2>  
					                  <!--<p> Fall 2021 - Spring 2022: Self-supervised and federated learning for audio source separation.<br>-->
					                  <!--Fall 2018 - Spring 2020: Performing <strong>unsupervised audio source separation</strong> using <strong>deep clustering</strong>.-->
					                  <!--Developing cost-efficient neural architectures for <strong>universal sound source separation</strong>.</p>-->
					                  <!--Spring 2021: Teaching assistant for the course <strong>CS 446 Machine learning</strong>.<br>-->
					                  <!--Fall 2020: Teaching assistant for the course <strong>CS 598 Machine learning for signal processing</strong>.-->
					               </div>
					            </div>
					         </article>
				             
				             <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/fb_research_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Intern at
									<a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Facebook Reality Labs (FRL)</a>
									<br> <span> <strong>Redmond, Washington, USA</strong> | May 2021 - Aug 2021</span> </h2>  
					                  <p> Self-supervised speech enhancement at scale.</p>
					               </div>
					            </div>
					         </article>
					         
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/google_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Student Researcher at
									<a href="https://ai.google/">Google AI</a>
									<br> <span> <strong>Urbana, Illinois, USA</strong> | Aug 2020 - May 2021</span> </h2>  
					                  <p> In-the-wild audio-visual universal sound source separation of on-screen sounds.</p>
					               </div>
					            </div>
					         </article>
					         
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/google_logo.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Intern at
									<a href="https://ai.google/">Google AI</a>
									<br> <span> <strong>Cambridge, Massachusetts, USA</strong> | May 2020 - Aug 2020</span> </h2>  
					                  <p> Unsupervised single-channel universal source separation using mixtures of mixtures. <strong>Purely unsupervised mixture invariant training</strong>
					                  obtains comparable results to fully supervised approaches!</p>
					               </div>
					            </div>
					         </article>
					         
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					                <!--<div class="timeline-entry-inner"> <div class="timeline-icon color-none"> </div> </div>-->
					               <div class="timeline-icon color-3">
									  <img class='timeline-image' src='images/google_ai.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Intern at
									<a href="https://ai.google/">Google AI</a>
									<br> <span> <strong>Cambridge, Massachusetts, USA</strong> | May 2019 - Aug 2019</span> </h2>  
					                  <p> Exploiting high-level <strong>semantic representations of sounds</strong> in order to boost the performance
					                  of universal sound source separation systems. The proposed architecture <strong>improved the
					                  state-of-the-art</strong>
					                  on sound separation when a variety of types of source signals might be active <strong>without the need of additional labels</strong>.</p>
					               </div>
					            </div>
					         </article>
			
					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
										<img class='timeline-image' src='images/bsi.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Machine Learning Engineer at
									<a href="https://behavioralsignals.com/">Behavioral Signals</a>
									<br> <span> <strong>Los Angeles, California, USA</strong> | May 2017 - Jul 2018</span> </h2>  
					                  <p><strong>Leading</strong> the machine learning infrastructure development.
									  Building <strong>state-of-the-art</strong> models for speech emotion recognition
									  and integrating them into product-level solutions. <strong>Automating</strong> the
									  procedure of inference by implementing <strong>dynamic graph pipelines</strong>
									  and <strong>optimizing</strong> feature extraction algorithms in Python.</p>
					               </div>
					            </div>
					         </article>
							 
							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
										<img class='timeline-image' src='images/athena_rc.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Junior Researcher at
									<a href="https://www.athena-innovation.gr/en">ATHENA Research Center</a>
									<br> <span> <strong>Athens, Greece</strong> | May 2016 - Jul 2018</span> </h2>  
					                  <p> Building modelfs for real time speech emotion recognition
									  and multimodal engagement detection (European project:
									  <a href="http://babyrobot.eu/">BabyRobot</a>).</p>
					               </div>
					            </div>
					         </article>
							 
							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
										<img class='timeline-image' src='images/SBA_Research.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>Research Intern at
									<a href="https://www.sba-research.org/">SBA Research</a>
									(<a href="https://iaeste.org/">IAESTE</a>
									traineeship program)
									<br> <span> <strong>Vienna, Austria</strong> | Jul 2016 - Aug 2016</span> </h2>  
					                  <p>End-2-end implementation (circuit level connections,
									    BLE microprocessor programming, message encryption,
										Linux/Windows drivers and front-ends)
										of an automatic screen locker for increased computer security.</p>
					               </div>
					            </div>
					         </article>
							 
							 
							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
										<img class='timeline-image' src='images/ey.jpg'>
					               </div>
					               <div class="timeline-label">
					               	<h2>IT Advisory Intern at
									<a href="https://www.ey.com/en_gl">Ernst and Young</a>
									<br> <span> <strong>Athens, Greece</strong> | Jul 2015 - Oct 2015</span> </h2>  
					                  <p>Working at <a href="https://www.piraeusbank.gr/en/idiwtes">Piraeus Bank</a>'s database maintenance
									  as an external partner. Performing financial data analysis
									  and risk prediction.</p>
					               </div>
					            </div>
					         </article>
							 
							 
							 <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									 <img class='timeline-image' src='images/classroom.png'> </a>
										<!--<img class='timeline-image' src='images/ey.jpg'></img>-->
					               </div>
					               <div class="timeline-label">
					               	<h2>Private Tutor
									<br> <span> <strong>Athens, Greece</strong>
									 | May 2013 - Jun 2017</span> </h2>  
					                  <p>Selected courses given: Maths, Physics, Differential Analysis, Algorithms.</p>
					               </div>
					            </div>
					         </article>
							 
			
			
					         <article class="timeline-entry begin animate-box" data-animate-effect="fadeInBottom">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-none">
					               </div>
					            </div>
					         </article>
					         
					      </div>
					   </div>
				   </div>
				</div>
					
<!--				<p style="text-align: center" class="animate-box" data-animate-effect="fadeInBottom">-->
<!--					For more information, please check my <a href="./files/academic_cv_etzinis.pdf">academic CV</a>.</p>-->
					
			</section>
			
			
			<section class="colorlib-about" data-section="papers">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">My contribution</span>
										<h2 class="colorlib-heading">Selected Research Papers</h2>
									</div>
								</div>
							</div>
							<div class="row" >
								<div class="animate-box" data-animate-effect="fadeInRight">
									<ul class="research-papers-list">
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Adi Y., Ithapu, V. K., Xu B., Smaragdis, P., Kumar, A., 
									<em>"RemixIT: Continual self-training of speech enhancement models via bootstrapped remixing."</em>
                                    To appear in <em>Journal of Selected Topics in Signal Processing (JSTSP)</em>, 2022.
                                    <a href="https://doi.org/10.1109/JSTSP.2022.3200911">[DOI]</a>
									<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9864253">[pdf]</a>
									<a href="https://www.youtube.com/watch?v=ApkuD9QVlqw">[video]</a>.
									</span>
									</li>    
									
									<li><span>
									<strong>Tzinis, E.</strong>, Wisdom, Remez, T., and Hershey, J. R.,
									<em>"AudioScopeV2: Audio-Visual Attention Architectures for Calibrated Open-Domain On-Screen Sound Separation."</em>
									<!--To appear in <em>International Conference on Learning Representations (ICLR)</em>, 2021.-->
									<a href="https://arxiv.org/pdf/2207.10141.pdf">[pdf]</a>
									<a href="https://github.com/google-research/sound-separation/tree/master/datasets/audioscope-v2">[datasets]</a>
									<a href="https://www.youtube.com/watch?v=6UgcS3NdPn8">[video]</a>
									<a href="https://docs.google.com/presentation/d/1qpweESDR-NEO7kvP7bkkgahehnmeQi_bKG6R3OL23Jo/edit?usp=sharing">[poster]</a>
									<a href="https://docs.google.com/presentation/d/1cJm5HdXy_IWjVtp4tW7q84y9Nq-8LDHm/edit?usp=sharing&ouid=106534973647151270598&rtpof=true&sd=true">[slides]</a>
									<a href="https://google-research.github.io/sound-separation/papers/audioscope-v2/">[website]</a>.
									</span>
									</li>    
									
									<li><span>
									<strong>Tzinis, E.</strong>, Wichern G., Subramanian, A., Smaragdis, P., and Le Roux, J.,
									<em>"Heterogeneous target speech separation."</em>
                                    In Proceedings of <em>Interspeech</em>, 2022.
									<a href="https://doi.org/10.21437/Interspeech.2022-10717">[DOI]</a>
									<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/tzinis22_interspeech.pdf">[pdf]</a>,
									<a href="https://github.com/etzinis/heterogeneous_separation">[code]</a>
                                    <a href="https://www.youtube.com/watch?v=tPjGSuBcGA4">[video]</a>
									<a href="https://docs.google.com/presentation/d/15dUDG-qiX0QABBeGZ1f7pmZwtGshSp6w/edit?usp=sharing&ouid=106534973647151270598&rtpof=true&sd=true">[slides]</a>
									<a href="https://etzinis.github.io/projects_demos/heterogeneous.html">[audio-samples]</a>.
									</span>
									</li>   
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Adi Y., Ithapu, V. K., Xu B., Kumar, A., 
									<em>"Continual self-training with bootstrapped remixing for speech enhancement."</em>
                                    In Procedings of <em>International Conference of Acoustics, Speech and Signal Processing (ICASSP)</em>, 2022.
									<a href="https://doi.org/10.1109/ICASSP43922.2022.9747463">[DOI]</a>
									<a href="https://arxiv.org/pdf/2110.10103.pdf">[pdf]</a>
									<a href="https://www.youtube.com/watch?v=ApkuD9QVlqw">[video]</a>
									<a href="https://drive.google.com/file/d/1HPIJzB8zubGVj-KIfO9kYLL8Crgxj_ic/view">[poster]</a>
									<a href="https://drive.google.com/file/d/1bkJsaXSAkFm0Sl5N3pFo1eo4QJpsayHB/view">[slides]</a>.
									</span>
									</li>
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Casebeer, J., Wang, Z., and Smaragdis, P.,
									<em>"Separate but Together: Unsupervised Federated Learning for Speech Enhancement from non-IID Data."</em>
									In Proceedings of <em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em>, 2021.
									<a href="https://doi.org/10.1109/WASPAA52581.2021.9632783">[DOI]</a>
									<a href="https://arxiv.org/pdf/2105.04727.pdf">[pdf]</a>
									<a href="https://github.com/etzinis/fedenhance">[code]</a>
									<a href="https://www.youtube.com/watch?v=nJ8knZGaUKg">[video]</a>
									<a href="https://drive.google.com/file/d/12osKk_mcyxv7EpX_A-PpWmLnuh99uSWM/view?usp=sharing">[slides]</a>.
									</span>
									</li>        
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Wisdom, S., Jensen, A., Hershey, S., Remez, T., Ellis, D. P., and Hershey, J. R.,
									<em>"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds."</em>
									In Proceedings of <em>International Conference on Learning Representations (ICLR)</em>, 2021.
									<a href="https://openreview.net/forum?id=MDsQkFP1Aw">[DOI]</a>
									<a href="https://openreview.net/pdf?id=MDsQkFP1Aw">[pdf]</a>
									<a href="https://audioscope.github.io">[website]</a>
									<a href="https://slideslive.com/38954059/into-the-wild-with-audioscope-unsupervised-audiovisual-separation-of-onscreen-sounds">[video]</a>
									<a href="https://iclr.cc/media/Slides/iclr/2021/virtual(03-16-00)-03-16-00UTC-3161-into_the_wild.pdf">[slides]</a>.
									</span>
									</li>
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Bralios, D., and Smaragdis, P.,
									<em>"Unified Gradient Reweighting for Model Biasing with Applications to Source Separation."</em>
									In Proceedings of <em>International Conference in Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021.
									<a href="https://doi.org/10.1109/ICASSP39728.2021.9414071">[DOI]</a>
									<a href="https://arxiv.org/pdf/2010.13228.pdf">[pdf]</a>
									<a href="https://github.com/etzinis/biased_separation">[code]</a>
									<a href="https://www.youtube.com/watch?v=cEW82Pk2iKY">[video]</a>.
									</span>
									</li>   
									    
									<!--<li><span>-->
									<!--<strong>Tzinis, E.</strong>, Wisdom, S., Jensen, A., Hershey, S., Remez, T., Ellis, D. P., and Hershey, J. R.-->
									<!--<em>"Self-Supervised Audio-Visual Separation of On-Screen Sounds from Unlabeled Video."</em>-->
									<!--In <em>Self-Supervised Learning for Speech and Audio Processing Workshop (NeurIPS) 2020</em>,-->
									<!--<a href="https://neurips-sas-2020.github.io/#papers">[workshop]</a>-->
									<!--<a href="https://drive.google.com/file/d/1t6wPaWLXY6a0sy6ch4fLA_b1yk9n6y3R/view">[pdf]</a>-->
									<!--<a href="https://slideslive.com/38942041">[video]</a>.-->
									<!--</span>-->
									<!--</li>  -->
									    
									<li><span>
									Wisdom, S., <strong>Tzinis, E.</strong>, Erdogan, H., Weiss, R. J., Wilson, K., and Hershey, J. R.,
									<em>"Unsupervised Sound Separation Using Mixtures of Mixtures."</em>
									In Proceedings of <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020.
									<a href="https://papers.nips.cc/paper/2020/hash/28538c394c36e4d5ea8ff5ad60562a93-Abstract.html">[DOI]</a>
									<a href="https://papers.nips.cc/paper/2020/file/28538c394c36e4d5ea8ff5ad60562a93-Paper.pdf">[pdf]</a>
									<a href="https://slideslive.at/38937996/unsupervised-sound-separation-using-mixture-invariant-training?ref=speaker-38272-latest">[video]</a>.
									</span>
									</li>    
									    
									<li><span>
									<strong>Tzinis, E.</strong>,Wang, Z., and Smaragdis, P.,
									<em>"Sudo rm -rf: Efficient Networks for Universal Audio Source Separation."</em>
									In Proceedings of <em>IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em>, 2020.
									<a href="https://papers.nips.cc/paper/2020/hash/28538c394c36e4d5ea8ff5ad60562a93-Abstract.html">[DOI]</a>
									<a href="https://arxiv.org/pdf/2007.06833.pdf">[pdf]</a>
									<a href="https://github.com/etzinis/sudo_rm_rf">[code]</a>
									<a href="https://www.youtube.com/watch?v=ftc0-tTf4O8">[video]</a>.
									</span>
									</li>
									    
									<li><span>
									<strong>Tzinis, E.</strong>, Venkataramani, S., Wang, Z., Subakan, Y. C., and Smaragdis, P.,
									<em>"Two-Step Sound Source Separation: Training on Learned Latent Targets."</em>
									In Proceedings of <em>International Conference in Acoustics, Speech and Signal Processing (ICASSP)</em>, 2020.
									<a href="https://ieeexplore.ieee.org/document/9054172">[DOI]</a>
									<a href="https://arxiv.org/pdf/1910.09804.pdf">[pdf]</a>
									<a href="https://github.com/etzinis/two_step_mask_learning">[code]</a>
									<a href="https://www.youtube.com/watch?v=C0okWxdFWU4">[video]</a>.
									</span>
									</li>
									
									<li><span>
									<strong>Tzinis, E.</strong>, Wisdom, S., Hershey, J.R., Jansen, A. and Ellis, D.P.,
									<em>"Improving Universal Sound Separation Using Sound Classification."</em>
									In Proceedings of <em>International Conference in Acoustics, Speech and Signal Processing (ICASSP)</em>, 2020
									<a href="https://ieeexplore.ieee.org/document/9053921">[DOI]</a>
									<a href="https://arxiv.org/pdf/1911.07951.pdf">[pdf]</a>
									<a href="https://www.youtube.com/watch?v=_PfPQNlpBX0">[video]</a>.
									</span>
									</li>
										
									<li><span>
									<strong>Tzinis, E.</strong>, Venkataramani, S. and Smaragdis, P.,
									<em>"Unsupervised deep clustering for source separation: direct learning from mixtures using spatial information."</em>
									In Proceedings of <em>International Conference in Acoustics, Speech and Signal Processing (ICASSP)</em>, 2019, pp. 81-85. 
									<a href="https://ieeexplore.ieee.org/document/8683201">[DOI]</a>
									<a href="https://arxiv.org/pdf/1811.01531.pdf">[pdf]</a>
									<a href="https://github.com/etzinis/unsupervised_spatial_dc">[code]</a>
									</span>
									</li>
									
									<!--<li><span>-->
									<!--<strong>Tzinis, E.</strong> <span>&#8224;</span>,-->
									<!--Paraskevopoulos, G. <span>&#8224;</span>, Baziotis, C., and Potamianos, A.,-->
									<!--<em>"Integrating recurrence dynamics for speech emotion recognition."</em>-->
									<!--In <em>Proceedings of Interspeech 2018</em>, pp. 927-931.-->
									<!--<a href="https://doi.org/10.21437/Interspeech.2018-1377">[DOI]</a>-->
									<!--<a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1377.pdf">[pdf]</a>-->
									<!--<a href="https://github.com/etzinis/nldrp">[code]</a>-->
									<!--</span>-->
									<!--</li>-->
									
									<!--<li><span>-->
									<!--<strong>Tzinis, E.</strong>, and A. Potamianos,-->
									<!--<em>"Segment-based speech emotion recognition using recurrent neural networks."</em>-->
									<!--In Proceedings of <em> Affective Computing and Intelligent Interaction (ACII)</em>, 2017, pp. 190-195. -->
									<!--<a href="https://doi.org/10.1109/ACII.2017.8273599">[DOI]</a>-->
									<!--<a href="https://www.researchgate.net/profile/Efthymios_Tzinis/publication/319967989_Segment-Based_Speech_Emotion_Recognition_Using_Recurrent_Neural_Networks/links/59c41605458515548f219124/Segment-Based-Speech-Emotion-Recognition-Using-Recurrent-Neural-Networks.pdf">[pdf]</a>-->
									<!--<a href="https://github.com/etzinis/unsupervised_spatial_dc">[code]</a>-->
									<!--</span>-->
									<!--</li>-->
									
									</ul>
								</div>
								
								
								<p style="text-align: center; font-size: smaller;"
								   class="animate-box" data-animate-effect="fadeInBottom">
								<!--<span>&#8224;</span> Equal contribution.</p>-->
							
								
								<br>
					
							</div>
							
							<div class="row animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<h2 class="colorlib-heading">Theses</h2>
									</div>
								</div>
								
								
								
							</div>
							
							<div class="row" >
								<ul class="research-papers-list">
								<span class="animate-box" data-animate-effect="fadeInRight">
								<strong>Tzinis, E.</strong>, 
								<em>""Manifold Learning and Nonlinear Recurrence Dynamics for Speech Emotion Recognition on Various Timescales."</em>
								Diploma Thesis at the
								<em>National Technical University of Athens, Electrical and Computer Engineering (ECE) Department</em>.
								<a href="https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/47369/etzinis_thesis_english.pdf?sequence=1&isAllowed=y">[pdf]</a>
								<a href="https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/47369/etzinis_thesis_presentation.pdf?sequence=3&isAllowed=y">[slides]</a>
								</span>
								</ul>
							</div>
							
							<div class="row" >
								<ul class="research-papers-list">
								<span class="animate-box" data-animate-effect="fadeInRight">
								<strong>Tzinis, E.</strong>,
								<em>""Unsupervised sound separation."</em>
								Ph.D. dissertation at the
								<em>Computer Science department at the University of Illinois, Urbana-Champaign</em>.
									<a href="https://www.ideals.illinois.edu/items/127515">[pdf]</a>
									<a href="https://docs.google.com/presentation/d/1Ec7POwKlQwrk7j1-Qk0ZnpFNaJj-PmT1/edit?usp=sharing&ouid=106534973647151270598&rtpof=true&sd=true">[slides]</a>
								</span>
								</ul>
							</div>
							
							<br>
							
							<p style="text-align: center" class="animate-box" data-animate-effect="fadeInBottom">
								A full and always updated list of my research papers is also available at my 
								<a href="https://scholar.google.gr/citations?user=IuKsc4IAAAAJ&hl=en&oi=ao">
								scholar profile</a>.</p>
							
						</div>
					</div>
				</div>
			</section>
			
			
<!--			<section class="colorlib-contact" data-section="blog">-->
<!--				<div class="colorlib-narrow-content">-->
<!--					<div class="row">-->
<!--						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">-->
<!--							<span class="heading-meta">Project Demos</span>-->
<!--							<h2 class="colorlib-heading">Demos and Blog</h2>-->
<!--						</div>-->
<!--					</div>-->
<!--					-->
<!--					<p style="text-align: center" class="animate-box" data-animate-effect="fadeInBottom">-->
<!--					Feel free to enjoy some fancy audio-visual samples of past and ongoing-->
<!--					research work <a href="https://etzinis.github.io/projects_demos/">here</a>!-->
<!--					</p>-->
<!--					-->
<!--					 -->
<!--					-->
<!--				</div>-->
<!--				-->
<!--			</section>-->
			
	
			<section class="colorlib-contact" data-section="contact">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">Get in Touch</span>
							<h2 class="colorlib-heading">Contact Me</h2>
						</div>
					</div>
					
					<div class="row">
						
							
	
							<div class="colorlib-feature colorlib-feature-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="colorlib-icon" style="background: transparent;">
									<i class="icon-mail"></i>
								</div>
								<div class="colorlib-text">Email me at:
								<a href="mailto:etzinis@google.com">etzinis@google.com</a>
								</div>
							</div>
	
							<div class="colorlib-feature colorlib-feature-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="colorlib-icon" style="background: transparent;">
									<i class="icon-location-outline"></i>
								</div>
								<div class="colorlib-text">My office is located at
								<a href="https://maps.app.goo.gl/ueBgx4TGWkyAbjgY9">
								Google in Cambridge, MA, USA</a>
								</div>
							</div>
							
							
							
							
							
					</div> <br style="margin-bottom: 120px"></br> 
					
					<p style="text-align: center" class="animate-box" data-animate-effect="fadeInBottom">
					<em>“Γυμνοί ήλθομεν οι πάντες, γυμνοί και απελευσόμεθα.”</em> <br>
					Αίσωπος, 620-560 π.Χ. <br>
					<em>“We were all born naked and this is how we are going to die.”</em> <br>
					Asopus, 620-560 BCE <br style="margin-bottom: 90px"> </br>
					
					Efthymios Tzinis &copy 2024 <br>
					
                    <div align=center>Congrats, you are the <a ref='https://www.counter12.com'><img src='https://www.counter12.com/img-a5AAcyw2WbxBWwBb-5.gif' border='0' alt='counter free'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=a5AAcyw2WbxBWwBb'></script>-th visitor!</div>					
					</p>
					
					 
					
				</div>
				
			</section>
			
			</div><!-- end:colorlib-main -->
		</div><!-- end:container-wrap --> 
	</div><!-- end:colorlib-page -->
	
	
	<!--<script type="text/javascript">-->
	<!--particlesJS("js/particles.js");-->
	<!--</script>-->

	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>
	
	<script src="js/load-more-button.js"></script>
	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

